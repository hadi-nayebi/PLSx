{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc85b26c-9c51-467c-a469-93775f26dc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c514aa2-13ac-47be-8ed2-e07778b0af55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hadinayebi/CodingProjects/plsx\n"
     ]
    }
   ],
   "source": [
    "from PLSx.dataloader.dataloader import DataLoader\n",
    "from torch import device, cuda\n",
    "from PLSx.utils.file_manager import get_root\n",
    "root = get_root(file=\"./\", retrace=0)\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "981387e5-de23-4a53-bb1c-0965d3913052",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader()\n",
    "data_loader.train_data = \"clss\"\n",
    "device = device(\"cuda:0\" if cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eb60c84-f5a1-48ab-af44-52d861ab236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.transform_data(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16c60e3b-e65a-47a6-a740-d7a436918807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d11d7d76-3122-4a67-9a51-3a675c294812",
   "metadata": {},
   "outputs": [],
   "source": [
    "_data_loader = data_loader.get_train_batch(batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79ca2b3e-cd2c-4fbf-a647-cea7605d0f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[20.,  8.,  0.],\n",
      "        [20.,  8.,  0.],\n",
      "        [20.,  8.,  0.],\n",
      "        ...,\n",
      "        [20.,  8.,  0.],\n",
      "        [20.,  8.,  0.],\n",
      "        [20.,  8.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "for item in _data_loader:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b415854-87ea-48fe-8d94-0c67f1638b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1068, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9dc7a5-ca07-4786-9405-9953f55bdaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4682859a-b4ed-423d-b511-9a03e42d8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bac46475-6b18-4da7-9765-e0b6e6729560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PLSx.autoencoder.autoencoder import Autoencoder\n",
    "# from PLSx.autoencoder.architecture import Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7296cf78-5988-4f23-a400-70f6e6bd26cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture_json_file = root / \"PLSx\" / \"test_data\" / \"architecture_sample.json\"\n",
    "# architecture = Architecture()\n",
    "# architecture.build(architecture_json_file)\n",
    "# ae = Autoencoder(architecture=architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68da9b50-3dec-45f3-a180-fb2329356867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ndx, target_vals_ss, target_vals_cl, one_hot_input = ae.transform_input(item, device, input_keys=\"ASC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603f8e13-9815-4965-b034-91a15e50f7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "141381b0-611f-4481-980c-11e8fcf64426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20., 20., 20.,  ..., 20., 20., 20.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ff111-7a82-40ab-95db-84011716879c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db6e1308-aba6-4ce1-b301-f63b5b45a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39ec1fa9-bffd-4194-8303-9dbef985066e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1068, 21])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define input sequence\n",
    "sequence = one_hot(item[:, 0].long(), num_classes=21) * 1.0\n",
    "sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8933c95-8fb7-47a6-973a-bad0e63407bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input into [samples, timesteps, features]\n",
    "features = sequence.shape[1]\n",
    "n_in = sequence.shape[0]\n",
    "sequence = sequence.reshape((1, n_in, features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d538cd0-ad3f-4cbc-894e-fe5bf38c2db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b67becec-4dc0-435a-a47b-796bc8c64164",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'activation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9t/ry2pfm0s32s2y1bmxp8lv2800000gn/T/ipykernel_94604/2229914866.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model = Sequential(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model.add(RepeatVector(n_in))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_expected_cell_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'activation'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, seq_len, n_features, embedding_dim=32):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.seq_len, self.n_features = seq_len, n_features\n",
    "        self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim\n",
    "        self.rnn1 = nn.LSTM(\n",
    "        input_size=n_features,\n",
    "        hidden_size=self.hidden_dim,\n",
    "        num_layers=1,\n",
    "        batch_first=True\n",
    "        )\n",
    "        self.rnn2 = nn.LSTM(\n",
    "        input_size=self.hidden_dim,\n",
    "        hidden_size=embedding_dim,\n",
    "        num_layers=1,\n",
    "        batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((1, self.seq_len, self.n_features))\n",
    "        x, (_, _) = self.rnn1(x)\n",
    "        x, (hidden_n, _) = self.rnn2(x)\n",
    "        return hidden_n.reshape((self.n_features, self.embedding_dim))\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, seq_len, n_features, input_dim=32):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.seq_len, self.input_dim = seq_len, input_dim\n",
    "        self.hidden_dim, self.n_features = 2 * input_dim, n_features\n",
    "        self.rnn1 = nn.LSTM(\n",
    "        input_size=input_dim,\n",
    "        hidden_size=input_dim,\n",
    "        num_layers=1,\n",
    "        batch_first=True\n",
    "        )\n",
    "        self.rnn2 = nn.LSTM(\n",
    "        input_size=input_dim,\n",
    "        hidden_size=self.hidden_dim,\n",
    "        num_layers=1,\n",
    "        batch_first=True\n",
    "        )\n",
    "        self.output_layer = nn.Linear(self.hidden_dim, n_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.repeat(self.seq_len, self.n_features)\n",
    "        x = x.reshape((self.n_features, self.seq_len, self.input_dim))\n",
    "        x, (hidden_n, cell_n) = self.rnn1(x)\n",
    "        x, (hidden_n, cell_n) = self.rnn2(x)\n",
    "        x = x.reshape((self.seq_len, self.hidden_dim))\n",
    "        return self.output_layer(x)\n",
    "\n",
    "\n",
    "class LSTMAE(nn.Module):\n",
    "    def __init__(self, seq_len, n_features, embedding_dim=32):\n",
    "        super(LSTMAE, self).__init__()\n",
    "        self.encoder = Encoder(seq_len, n_features, embedding_dim).to(device)\n",
    "        self.decoder = Decoder(seq_len, n_features, embedding_dim).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb3d46a-0cd7-4037-ba5e-b5e3d52b34ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd1cbf-8ebf-4a2f-ab42-4acbb0e80a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
